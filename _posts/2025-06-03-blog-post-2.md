---
title: 'Domingos (2012) - A Few Useful Things to Know about Machine Learning'
date: 2025-06-03
permalink: /posts/2025/06/blog-post-2/
excerpt: "High-level overview of practical ML principles."
tags:
  - ML
---

## 1. Introduction

Machine learning ahs become pervasive across domains like web search, spam filtering, recommender systems, etc. While textbooks cover algorithms, real-world success often hinges on folk knowledge — practical insights that are rarely formalised.

The author presents key lessons that form the informal but vital backbone of effective machine learning practice.

## 2. Learning = Representation + Evaluation + Optimisation

- Representation: Defines the hypothesis space. Choosing a representation is like choosing which "language" the  model can speak. If the concept one wants to learn cannot be expressed in that language, it cannot be learned.
- Evaluation: Measures how well a hypothesis performs.  
- Optimization: Navigates the space to find the best hypothesis.

<p align="center">
  <img src="/images/post/post-2-1.png" alt="core_of_ml" width="100%">
</p>

## 3. It’s Generalisation that Counts

Overfitting happens when a model memorizes the training set but fails on unseen data. Real success in ML is about generalizing — performing well on new, unseen inputs.
- Use train/test splits or cross-validation to assess generalization.
- Avoid contaminating training with test data.

## 4. Data Alone is Not Enough

Even with large datasets, generalisation requires inductive bias — assumptions that guide learning beyond the observed data.
- No free lunch theorem: Over all possible tasks, no learner beats random guessing.
- The hypothesis space must reflect domain knowledge.

Seeds do not grow without soil. Data is the seed, but domain knowledge is the soil.

## 5. Overfitting has Many Faces

<p align="center">
  <img src="/images/post/post-2-2.png" alt="bias_var" width="60%">
</p>

Overfitting is not just noise fitting. It also arises from models being too flexible.
- Bias-Variance Tradeoff:
  - High bias: Learns too simple a model.
  - High variance: Learns noise as signal.

- Methods to mitigate:
  - Cross-validation
  - Regularisation terms
  - Statistical tests

## 6. Intuition Fails in High Dimensions

- Problem: As feature dimension increases 
  - Data becomes sparse and uniform.
  - Similarity metrics fail.

- Solution: 
  - Feature selection/engineering
  - Dimensionality reduction

## Theoretical Guarantees are Not What They Seem

PAC-style bounds are impractical as
- Bounds scale poorly with dimension.
- Often overestimate required data.
- Union bounds are pessimistic.

It is like saying "you are guaranteed not to drown if you wear 10 life jackets" — overkill, and often unnecessary.

## Feature Engineering is Key

Better features are more important than better algorithms. Features embody domain knowledge and they reduce the complexity of learning. Most project time is on data processing and feature selection.

## More Data Beats a Clever Algorithm
Given enough data, simple algorithms often outperform complex ones. For practical implications, invest in data collection pipeliknes, and embrace the scaling power of simplicity.

It is like fertiliser (data) growing crops better than tractor (algorithm) tinkering.

## Learn Many Models, Not Just One
Model ensembles (bagging, boosting, stacking) outperform single models because
- Reduce variance.
- Stabilise predictions.
- Combine diverse inductive biases.

## Simplicity Does Not Imply Accuracy
There are a few counterexamples where shorter code does not guarantee better generalisation.

## Representable Does Not Imply Learnable
Just because a function can be represented or approximated by a model class does not mean a learning algorithm can discover it.

A library (representation) may contain every book (function), but if you don’t know the catalog system (optimization), or if your flashlight (data) is too dim, you’ll never find the right book.

## Correlation Does Not Imply Causation
ML usually relies on observational data, not experiments. Correlation may mislead action-oriented decisions.
Solution is to run A/B tests when possible and be cautious about using ML for decision policies.

Buying diapers does not cause beer sales — but they co-occur.